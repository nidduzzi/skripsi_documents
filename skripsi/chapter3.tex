% !TEX root = ./skripsi.tex
\chapter{RESEARCH METHODOLOGY}\label{sec:research_methodology}

% Secara umum, metode penelitian yang digunakan pada pekerjaan penelitian disampaikan pada bab ini. Judul bab tidak harus seperti yang dituliskan. Dalam kata lain bisa diubah sesuai kebutuhan.

\section{Research Design}
\noindent This study is carried out under the framework of a research design. In this section, this design will be laid out and explained. The design includes the process from the beginning to the end of the overall study. The research design is visually depicted in \lccref{fig:research_design_diagram}.

\begin{figure}[h]
      \centering
      \tikzfig{figures/research_design_diagram}
      \caption{Research design diagram}\label{fig:research_design_diagram}
\end{figure}

The study is carried out in 9 main phases. Each phase has a specific aim to accomplish such that the subsequent phases are able to proceed. Each phase is explained as follows:

\begin{enumerate}
      \item Problem Specification

            In this phase, relevant literature of related works and other supporting materials will be reviewed to lay the groundwork of this study. Specifically, the literature review will encompass partial differential equations and their real world associations, traditional methods employed to solve them, systems with partially known or unknown governing equations, machine learning approaches to the problem, least-squares support vector machines, performance metrics and tools that will be used such as the PyTorch library.

      \item Design of Computational Model

            This phase of the study is allocated to the design of the computational model based on the literature that has been reviewed. The design of the overall process includes data retrieval, preprocessing, and the core spectral regression model itself.

      \item Implementation of Computational Model

            After the computational model design is completed, the model is implemented in the Python Language using the PyTorch library as a core component. Implementation of the computational model is done using an iterative software development model. This development model was chosen due to its adaptability to unexpected challenges which is necessary because of the challenges and unknowns with developing a novel method.

      \item Planning of Experimental Scenarios

            To properly gauge the performance of the proposed method at approximating operators, specifically the solution operator of partial differential equations, experimental scenarios are developed in this phase. Specifically, the scenarios serves three goals which are proof of concept or validation that the method is able to learn operators, a case study of a more complex system with real world data, and a using the model as a surrogate. Together, these experimental scenarios determine the applicability of the model to the problem. In addition, the model will be compared to a baseline model in order to put into context the proposed model's performance. In addition, kernel-input correlation matrices and input-Lagrangian multiplier inner product matrix will also be computed.

      \item Data Generation and Retrieval

            This phase of the study is tied to the experimental scenarios that have been developed. After determination of the scenario specifics, the data that will be used for training, validation, and testing of the model in each scenario will be either generated or retrieved from an external source. In addition, in each scenario the hyperparameters of the model will be determined using Bayesian optimization as an alternative to the traditional grid search method.

      \item Data Preprocessing

            The next phase after data generation or retrieval is preprocessing. This is a crucial step in allowing the core LSSVR to learn the mappings in spectral space. In order to do this, the data will need to be reshaped, and important features selected for. Finally, inputs to the LSSVR will need to be normalized or scaled such that the LSSVR model can much more easily learn the data.

      \item Experiments

            This phase of the study executes the experimental scenarios that was determined previously. The preprocessed data will be used in accordance to the preplanned scenarios.

      \item Analysis and Discussion

            The final phase of the study is the analysis and discussion of the results. Analysis of each experimental scenario will assess the extent of the model's capabilities. Another component of the analysis is interpretation the trained model and how it comes to the predictions that it makes. The discussion will also touch on the hyperparameter optimization and comparisons with the baseline model. This will show how the model performs differently compared to the baseline.
\end{enumerate}

\section{Literature Study Method}
\noindent As a basis for this study, information surrounding the topic is collected from literature sources such as books, journal articles, and other academic works like dissertations. The tools that are used to find these sources include Google Scholar and Google Search. The search terms used start with two terms which are partial differential equations and machine learning. Based on reading the most relevant literature, further search terms are created from variants of previous search terms combined with terms from literature that has been found.

\section{Data Generation and Retrieval Method}
\noindent Data to be used in this study are acquired in two different ways. The first method is data generation. This is motivated by the fact that some partial differential equations do not have much open and accessible real world data available. As such the systems are simulated using the equations themselves. In simple scenarios like computing the antiderivative \(u\) of some function \(f \), this can be done by randomly generating \(u\) and then taking their derivatives to compute \(f\). The random function generation itself is done by generating random coefficients for basis functions like the Fourier series. Once all functions are generated, random noise is added to ensure that the model is also robust towards inexact measurements. A diagram illustrating the process is shown in \lccref{fig:data_generation_diagram}.

\begin{figure}[H]
      \centering
      \begin{adjustbox}{max width=\textwidth}
            \tikzfig{figures/data_generation_diagram}
      \end{adjustbox}
      \caption{Data generation diagram}\label{fig:data_generation_diagram}
\end{figure}

Data retrieval is the other option which in this case is used to retrieve data for weather prediction. Based on the scenario the data is to be used for, relevant subsets of the dataset is retrieved to a working machine. This study specifically uses a dataset provided by the European Center for Medium Range Weather Forecast (ECMWF) named ERA5 hourly data on single levels from 1940 to present \autocite{c3sERA5HourlyData2018}. The first step is selecting a geographical area to study, time period, NetCDF4 data format, and variables such as temperature at 2 meters above the surface. Then the second step is specifications are then used to request the data through the climate data store application programming interface. The downloaded data is then parsed using the Xarray library and preprocessed.

\section{Computational Model Implementation Method}\label{sec:development_method}
\noindent Implementation of the computational model follows an iterative development model. This model basically consists of repeated cycles or iterations of software development. Each cycle is loosely based on the waterfall development model, namely the processes of requirement gathering, analysis \& design, implementation, and testing. This iterative property is crucial for this study because all the requirements cannot be known beforehand. This model minimizes the risk in developing complex software with partially known initial requirements. A diagram of the model can be seen in \lccref{fig:iterative_development_diagram}.

\begin{figure}[H]
      \centering
      \begin{adjustbox}{max width=\textwidth}
            \tikzfig{figures/iterative_development_diagram}
      \end{adjustbox}
      \caption{Iterative development model}\label{fig:iterative_development_diagram}
\end{figure}

This development model was adapted from \textcite{bittnerManagingIterativeSoftware2006}. Each process in the model is explained as follows:
\begin{enumerate}
      \item Initial Planning

            The first process of the iterative development model sets up the parameters for the iterative development. These parameters are the broad scope of the project and initial requirements such as core components like LSSVR\@. The initial requirements are crucial in guiding the rest of the development as more requirements are gathered. The initial planning also determines technical choices like tooling and choice of language. The planning process also includes a rough architecture based in initial requirements.

      \item Requirements

            This process separates out the backlog of requirements into those that will be worked on in the current iteration. These requirements ideally share some functionality in order to allow the same context to be retained within the iteration which reduces the burden of context switching.

      \item Analysis and Design

            This process an analysis of the requirements of the current iteration is performed. This involves determining the constraints and goals for each requirement. Constraints also need to consider previous iterations such that the requirements can be fulfilled effectively and efficiently without regressing progress that has been made such as breaking existing functionality. From this analysis, the design is updated so that the requirement can be fulfilled. The design itself informs how the code should be structured. The interfaces used in the code are also specified.

      \item Implementation

            The implementation process applies the design that has been produced. In addition to implementing the program, this process also implements tests which validate and verify the produced code. In the case of complex pieces of the design, an approach of creating tests and assertions first is taken. This way, the code can be run quickly and fail immediately to allow a quicker convergence on the intended functionality.

      \item Testing and Evaluation

            Once the design is implemented, tests that have been created are run. Each feature is tested in an integrated manner to expedite the process while still providing enough confidence in the software. The results of the testing process are evaluated and any failed tests are resolved whether by reimplementation or reassessment of the correctness of the tests. Any missing functionality or feature discovered during evaluation are added to the backlog of requirements.

      \item Release

            After an iteration, the current version of the software is released. The iterative nature of this development model necessitates the use of a versioning system. As such each release can be identified by a version number loosely based on semantic versioning \autocite{preston-wernerSemanticVersioning200}. This version numbering system consists of major number that indicates breaking changes, minor numbers which indicate features and non-breaking changes, and lastly patch numbers are used for fixes. A version number is read as \verb|MAJOR.MINOR.PATCH|. During active development, only major version 0 will be used to prevent too many major versions. The released software is hosted in its own GitHub repository at \url{https://github.com/nidduzzi/SpectralSVR}.

\end{enumerate}

\section{Research Tools}
\noindent The tools that are used in this study can be categorized into hardware and software. The following are hardware that are used in this study:
\begin{itemize}
      \item Kaggle CPU Kernel~\autocite{GettingStartedKaggle}
            \begin{itemize}
                  \item 4 Cores Intel Xeon
                  \item 30 Gigabytes RAM
                  \item 20 Gigabytes Working storage
            \end{itemize}
      \item Kaggle GPU Kernel~\autocite{GettingStartedKaggle}
            \begin{itemize}
                  \item 4 Cores Intel Xeon
                  \item 29 Gigabytes RAM
                  \item 1 Nvidia P100 GPU
                  \item 20 Gigabytes Working storage
            \end{itemize}
      \item Personal Computer
            \begin{itemize}
                  \item Intel i5{-}8300H
                  \item 16 Gigabytes RAM
                  \item Nvidia GeForce GTX 1060 Mobile
                  \item 1.5 Terabytes Storage
            \end{itemize}
\end{itemize}
The software tools used in this study are the following:
\begin{itemize}
      \item Python
      \item Jupyter Notebook
      \item Git
      \item Poetry Python package manager
      \item Web Browser
      \item \LaTeX{}
\end{itemize}
